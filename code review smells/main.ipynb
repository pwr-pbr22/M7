{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Inicjalizacja"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from evaluator import evaluate, calc_impact, create_functions_in_db, calc_prs_bugginess, overwrite_bugginess_function\n",
    "from definitions import Repository\n",
    "import db\n",
    "import smells\n",
    "import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "#plots size in inches\n",
    "plt.rcParams[\"figure.figsize\"] = (10,5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from configuration import ProjectConfiguration\n",
    "\n",
    "config = ProjectConfiguration()\n",
    "\n",
    "db.prepare(config.connstr)\n",
    "\n",
    "dbsession = db.get_session()\n",
    "create_functions_in_db(dbsession)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Ewaluacja"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "repo = config.project\n",
    "\n",
    "if dbsession.query(Repository).filter(Repository.full_name == repo).first() is None:\n",
    "    raise LookupError(\"Repository does not exist\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Udział smelly prs wśród badanych prs (reprodukcja)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "smells_evaluations = [\n",
    "    evaluate(repo, smells.lack_of_review),\n",
    "    evaluate(repo, smells.missing_description),\n",
    "    evaluate(repo, smells.large_changesets),\n",
    "    evaluate(repo, smells.sleeping_reviews),\n",
    "    evaluate(repo, smells.review_buddies),\n",
    "    evaluate(repo, smells.ping_pong),\n",
    "    evaluate(repo, smells.union,\n",
    "         [smells.lack_of_review,\n",
    "          smells.missing_description,\n",
    "          smells.large_changesets,\n",
    "          smells.sleeping_reviews,\n",
    "          smells.review_buddies,\n",
    "          smells.ping_pong]),\n",
    "    evaluate(repo, smells.intersection,\n",
    "         [smells.lack_of_review,\n",
    "          smells.missing_description,\n",
    "          smells.large_changesets,\n",
    "          smells.sleeping_reviews,\n",
    "          smells.review_buddies,\n",
    "          smells.ping_pong])\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# display results as a text\n",
    "for evaluation in smells_evaluations:\n",
    "    print(evaluation)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# display results as a plot\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "xs = list(map(lambda e: e.evaluator_name.split(\"\\n\")[0], smells_evaluations))\n",
    "ys = list(map(lambda e: e.percentage*100, smells_evaluations))\n",
    "ax.barh(xs, 100, color=\"forestgreen\", label=\"non-smelly prs\")\n",
    "ax.barh(xs, ys, color=\"red\", label=\"smelly prs\")\n",
    "for i, v in enumerate(ys):\n",
    "    ax.text(101, i + 0.1, f\"{int(v)}%\", color=\"red\")\n",
    "    ax.text(105, i + 0.1, f\"{100-int(v)}%\", color=\"green\")\n",
    "ax.invert_yaxis()\n",
    "plt.legend(loc=\"upper center\", bbox_to_anchor=(0.5, -0.1))\n",
    "plt.title(f\"Percentage of smelly and non-smelly prs in {repo}\")\n",
    "plt.margins(x=0.1)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Wpływ smelli na prawdopodobieństwo wprowadzenia błędu"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# evaluate for smells impact\n",
    "impact_evaluations = list(map(lambda pair: (pair[0], calc_impact(session = dbsession,\n",
    "                                                                 repo = dbsession.query(Repository).filter(Repository.full_name == repo).first(),\n",
    "                                                                 evaluator = pair[1],\n",
    "                                                                 evaluator_args=None)), [\n",
    "    (\"Lack of code review\", smells.lack_of_review),\n",
    "    (\"Missing PR description\", smells.missing_description),\n",
    "    (\"Large changeset\", smells.large_changesets),\n",
    "    (\"Sleeping reviews\", smells.sleeping_reviews),\n",
    "    (\"Review Buddies\", smells.review_buddies),\n",
    "    (\"Ping-pong reviews\", smells.ping_pong)\n",
    "]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# display results as text\n",
    "print(\n",
    "    f\"Percentage of pulls where at least one file was changed next by bug solving PR:\")\n",
    "print(f\"{''.ljust(30)}OK    \\t SMELLY\\t IMPACT\")\n",
    "\n",
    "for (name, res) in impact_evaluations:\n",
    "    print(f\"{name.ljust(30)}{(res[0] * 100):.2f}%\\t {(res[1] * 100):.2f}%\\t {'+' if res[1]>res[0] else ''}{((res[1]-res[0]) * 100):.2f}%\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# display results as a plot\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "xs = list(map(lambda e: e[0], impact_evaluations))\n",
    "for_ok = list(map(lambda e: e[1][0]*100, impact_evaluations))\n",
    "for_smelly = list(map(lambda e: e[1][1]*100, impact_evaluations))\n",
    "ind = np.arange(len(xs))\n",
    "width = 0.4\n",
    "\n",
    "ax.barh(ind, for_ok, width, color=\"forestgreen\", label=\"Percentage for non-smelly\")\n",
    "for i, v in enumerate(for_ok):\n",
    "    ax.text((v + 1 if v<95 else 95) if v==v else 1, i + 0.1, f\"{int(v)}%\" if v==v else \"no prs\",  color=(\"green\" if v<95 else \"black\"))\n",
    "ax.barh(ind + width, for_smelly, width, color=\"red\", label=\"Percentage for smelly\")\n",
    "for i, v in enumerate(for_smelly):\n",
    "    ax.text((v + 1 if v<95 else 95) if v==v else 1, i + width + 0.1, f\"{int(v)}%\" if v==v else \"no prs\", color=(\"red\" if v<95 else \"black\"))\n",
    "ax.set(yticks=ind + width/2, yticklabels=xs, ylim=[2*width-1, len(xs)], xlim=[0, 100])\n",
    "ax.invert_yaxis()\n",
    "plt.legend(loc=\"upper center\", bbox_to_anchor=(0.5, -0.1))\n",
    "plt.title(f\"Percentage of pulls where at least one file was changed next by bug solving PR for {repo}\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Metryki"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from evaluator import get_considered_prs\n",
    "\n",
    "repo_obj = dbsession.query(Repository).filter(Repository.full_name == repo).first()\n",
    "prs = get_considered_prs(session = dbsession, repo = repo_obj)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Funkcja zliczająca metrykę bugginess może zostać częściowo nadpisana, domyślnie jest ona następująca:\n",
    "$\n",
    "\\left\\{\\begin{array}{ll}\n",
    "    f(0)=0 &\\\\\n",
    "    f(n)=f(x_{n-1})+\\frac{n^{-2}}{\\text{number of files in original PR}} &\\text{gdy n-ty PR zmieniający plik naprawia defektu}\\\\\n",
    "    f(n)=f(n-1) &\\text{gdy n-ty PR zmieniający plik nie naprawia defektu}\n",
    "  \\end{array}\\right.\n",
    "$\n",
    "\n",
    "Można nadpisać środkowe równanie.\n",
    "\n",
    "Domyślnie $n\\in[0; 4]\\cap\\mathbb{N}$, jednak głębokość przeszukiwania również może zostać nadpisana."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# bugginess function can be overwritten, below current expression\n",
    "# overwrite_bugginess_function(dbsession, \"res + pow(i,-2)/number_of_files\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "metrics_evaluations = [\n",
    "    metrics.review_window_metric(prs, repo_obj),\n",
    "    metrics.review_window_per_line_metric(prs, repo_obj),\n",
    "    calc_prs_bugginess(repo_obj, prs)\n",
    "    # can be changed for depth other than 4 (below no limit)\n",
    "    # calc_prs_bugginess(repo_obj, prs, depth=None)\n",
    "]\n",
    "\n",
    "# create dataframe\n",
    "df = pd.DataFrame()\n",
    "for m in metrics_evaluations:\n",
    "    df[m.metric_name] = m.to_list(dbsession)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# fig = plt.figure()\n",
    "# ax = fig.add_axes([0,0,1,1])\n",
    "# ax.boxplot(list(map(lambda m: m.to_list(dbsession), metrics_evaluations)),\n",
    "#     showfliers=False, notch=True, vert=False)\n",
    "# plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# calculate correlationn\n",
    "corr = df.corr()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# display correlation matrix\n",
    "print(corr)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# display correlation heatmap\n",
    "hm = sns.heatmap(corr, annot = True)\n",
    "hm.set(title = \"Correlation matrix of reviews metrics and bugginess metrics\\n\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# display plots of bugginess against each metrics\n",
    "upper_limit = df.quantile(0.95)\n",
    "\n",
    "fig, axs = plt.subplots(len(df.columns)-1)\n",
    "\n",
    "index = 0\n",
    "for column_name in df.columns[:-1]:\n",
    "    col = getattr(df, column_name)\n",
    "    xs = df[(col < upper_limit[column_name]) & (df.bugginess < upper_limit[\"bugginess\"])][column_name]\n",
    "    ys = df[(col < upper_limit[column_name]) & (df.bugginess < upper_limit[\"bugginess\"])][\"bugginess\"]\n",
    "    axs[index].plot(xs, ys, \"ro\")\n",
    "    axs[index].set_xlabel(f\"{column_name}\\nommited {len(df)-len(xs)} of {len(df)} prs\")\n",
    "    axs[index].set_ylabel(\"bugginess\")\n",
    "    index += 1\n",
    "\n",
    "plt.subplots_adjust(top=1, bottom=0, hspace=0.25, wspace=1)\n",
    "fig.set_figheight((len(df.columns)-1)*fig.get_figheight())\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}